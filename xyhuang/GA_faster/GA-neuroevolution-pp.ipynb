{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_xy\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.linalg import expm, logm\n",
    "import random\n",
    "from mpl_toolkits import mplot3d\n",
    "import scipy.integrate as integrate\n",
    "from sympy import lambdify, Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pauli(n):\n",
    "    if n==0:\n",
    "      return np.eye(2)\n",
    "    elif n==1:\n",
    "      return np.array([[0,1],[1,0]])\n",
    "    elif n==2:\n",
    "      return np.array([[0,-1j],[1j,0]])\n",
    "    elif n==3:\n",
    "      return np.array([[1,0],[0,-1]])\n",
    "    else:\n",
    "      raise ValueError('Input must be integer from 0 to 3.')\n",
    "\n",
    "# returns sigma_a^p*sigma_b^q, with a,b = 1,2,3, p,q being position\n",
    "def Kron2body(N_atom,a,b,p,q):\n",
    "    y=1\n",
    "    for i in range(N_atom):\n",
    "        if i==p:\n",
    "            y=np.kron(y,Pauli(a))\n",
    "        elif i==q:\n",
    "            y=np.kron(y,Pauli(b))\n",
    "        else:\n",
    "            y=np.kron(y,np.eye(2))\n",
    "    return y\n",
    "\n",
    "def Hamiltonian(N_atom,bc,cplist,model):\n",
    "    H=np.zeros((2**N_atom,2**N_atom))\n",
    "    for pp in range(len(cplist)):\n",
    "        for p in range(N_atom):\n",
    "            if bc=='p':\n",
    "                q=(p+pp+1)%N_atom\n",
    "            elif bc=='o':\n",
    "                q=p+pp+1\n",
    "                if q>=N_atom:\n",
    "                    continue\n",
    "            H=H+cplist[pp]*(model[0]*Kron2body(N_atom,1,1,p,q)\n",
    "                            +model[1]*Kron2body(N_atom,2,2,p,q)\n",
    "                            +model[2]*Kron2body(N_atom,3,3,p,q))+model[3]*Kron2body(N_atom,3,0,p,q)\n",
    "    if np.max(np.abs(np.imag(H)))<1e-10:                                         #why?\n",
    "        H=np.real(H)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleAI(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.fc = nn.Sequential(\n",
    "                        nn.Linear(13,64, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(64,64, bias=True),\n",
    "                        nn.ReLU(),\n",
    "#                         nn.Linear(128,128, bias=True),\n",
    "#                         nn.ReLU(),\n",
    "#                         nn.Linear(64,64, bias=True),\n",
    "#                         nn.ReLU(),\n",
    "                        nn.Linear(64,5, bias=True),\n",
    "                        nn.Softmax(dim=1)\n",
    "                        )##### first one state_dim=(e.g.13) last one action_dim=(e.g.5)\n",
    "\n",
    "                \n",
    "        def forward(self, inputs):\n",
    "            x = self.fc(inputs)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \n",
    "        # nn.Conv2d weights are of shape [16, 1, 3, 3] i.e. # number of filters, 1, stride, stride\n",
    "        # nn.Conv2d bias is of shape [16] i.e. # number of filters\n",
    "        \n",
    "        # nn.Linear weights are of shape [32, 24336] i.e. # number of input features, number of output features\n",
    "        # nn.Linear bias is of shape [32] i.e. # number of output features\n",
    "        \n",
    "        if ((type(m) == nn.Linear) | (type(m) == nn.Conv2d)):\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.00)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_random_agents(num_agents):\n",
    "    \n",
    "    agents = []\n",
    "    for _ in range(num_agents):\n",
    "        \n",
    "        agent = CartPoleAI()\n",
    "        \n",
    "        for param in agent.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        init_weights(agent)\n",
    "        agents.append(agent)\n",
    "        \n",
    "        \n",
    "    return agents\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents(agents):\n",
    "    \n",
    "    reward_agents = []\n",
    "    env = gym.make('xy-v0')\n",
    "    \n",
    "    \n",
    "    maxTime=12\n",
    "    nSpin=3\n",
    "    min_delay=0\n",
    "    max_delay=1\n",
    "    pw=0.5\n",
    "    env.setParam(maxTime,nSpin,min_delay,max_delay,pw)\n",
    "\n",
    "\n",
    "\n",
    "    Aim=np.zeros([2**nSpin,2**nSpin])\n",
    "    env.setTargetH(Aim)\n",
    "    env.setTarget(expm(-1j*Aim))\n",
    "    \n",
    "\n",
    "    H=Hamiltonian(nSpin,'p',[1],[-0.5,-0.5,1,0])\n",
    "    J=8.18e-3\n",
    "    env.setH0(J*H)   \n",
    "    env.set_pulse()\n",
    "    \n",
    "    for agent in agents:\n",
    "        agent.eval()\n",
    "    \n",
    "        observation,info = env.reset()\n",
    "        \n",
    "        r=0\n",
    "        s=0\n",
    "        \n",
    "        for i in range(maxTime):\n",
    "            \n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "#             print(inp)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            new_observation, reward, done, info = env.step(action,i)\n",
    "            r=r+reward\n",
    "            \n",
    "            s=s+1\n",
    "            observation = new_observation\n",
    "\n",
    "            if(done):\n",
    "                break\n",
    "\n",
    "        reward_agents.append(r)        \n",
    "        #reward_agents.append(s)\n",
    "        if r>16:\n",
    "            print(r)\n",
    "            print(observation)\n",
    "        \n",
    "    \n",
    "    return reward_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_average_score(agent, runs):\n",
    "    score = 0.\n",
    "    for i in range(runs):\n",
    "        score += run_agents([agent])[0]\n",
    "    return score/runs\n",
    "\n",
    "#     score=0.\n",
    "#     for i in range(runs):\n",
    "#         temp=run_agents([agent])[0]\n",
    "#         if temp>score:\n",
    "#              score = temp\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agents_n_times(agents, runs):\n",
    "    avg_score = []\n",
    "    for agent in agents:\n",
    "        avg_score.append(return_average_score(agent,runs))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "\n",
    "    child_agent = copy.deepcopy(agent)\n",
    "    \n",
    "    mutation_power = 0.005 #hyper-parameter, set from https://arxiv.org/pdf/1712.06567.pdf\n",
    "            \n",
    "    for param in child_agent.parameters():\n",
    "    \n",
    "        if(len(param.shape)==4): #weights of Conv2D\n",
    "\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    for i2 in range(param.shape[2]):\n",
    "                        for i3 in range(param.shape[3]):\n",
    "                            \n",
    "                            param[i0][i1][i2][i3]+= mutation_power * np.random.randn()\n",
    "                                \n",
    "                                    \n",
    "\n",
    "        elif(len(param.shape)==2): #weights of linear layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                for i1 in range(param.shape[1]):\n",
    "                    \n",
    "                    param[i0][i1]+= mutation_power * np.random.randn()\n",
    "                        \n",
    "\n",
    "        elif(len(param.shape)==1): #biases of linear layer or conv layer\n",
    "            for i0 in range(param.shape[0]):\n",
    "                \n",
    "                param[i0]+=mutation_power * np.random.randn()\n",
    "\n",
    "    return child_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate children from parents\n",
    "# agents stores the all agents in previous generation\n",
    "# sorted_parent_indexes stores the index of the agents that will give birth to children\n",
    "# elite_index is the best agent that will be stored in the last element of children_agents\n",
    "# n is the number of children to be generatated by mutating the parents, the rest of the agents will be randomly generated\n",
    "def return_children(agents, sorted_parent_indexes, elite_index, n):\n",
    "    n=np.min([n,len(agents)-1])\n",
    "    children_agents = []\n",
    "    \n",
    "    #first take selected parents from sorted_parent_indexes and generate N-1 children\n",
    "    for i in range(n):\n",
    "        selected_agent_index = sorted_parent_indexes[np.random.randint(len(sorted_parent_indexes))]\n",
    "        children_agents.append(mutate(agents[selected_agent_index]))\n",
    "        \n",
    "    for i in range(len(agents)-1-n):\n",
    "        children_agents.append(return_random_agents(1)[0])\n",
    "    #now add one elite\n",
    "    elite_child, top_score = add_elite(agents, sorted_parent_indexes, elite_index)\n",
    "    children_agents.append(elite_child)\n",
    "    elite_index=len(children_agents)-1 #it is the last one\n",
    "    \n",
    "    return children_agents, elite_index, top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elite(agents, sorted_parent_indexes, elite_index=None, only_consider_top_n=10):\n",
    "    \n",
    "    candidate_elite_index = sorted_parent_indexes[:only_consider_top_n]\n",
    "    \n",
    "    if(elite_index is not None):\n",
    "        candidate_elite_index = np.append(candidate_elite_index,[elite_index])\n",
    "        \n",
    "    top_score = None\n",
    "    top_elite_index = None\n",
    "    \n",
    "    for i in candidate_elite_index:\n",
    "        score = return_average_score(agents[i],runs=5)\n",
    "        print(\"Score for elite i \", i, \" is \", score)\n",
    "        \n",
    "        if(top_score is None):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "        elif(score > top_score):\n",
    "            top_score = score\n",
    "            top_elite_index = i\n",
    "            \n",
    "    print(\"Elite selected with index \",top_elite_index, \" and score\", top_score)\n",
    "    \n",
    "    child_agent = copy.deepcopy(agents[top_elite_index])\n",
    "    return child_agent, top_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def selection(n,rewards,topn):\n",
    "#     t0=1\n",
    "#     tf=1e-4\n",
    "#     yita=0.1\n",
    "#     lamb=1\n",
    "#     nc=21\n",
    "#     t=t0*(tf/t0)**(n/nc)*(1-yita*np.sin(lamb*np.pi*n/nc))\n",
    "#     qbest=np.amax(rewards)\n",
    "#     q=np.exp((rewards-qbest)/t)\n",
    "#     prob=q/np.sum(q)\n",
    "# #     print(list(enumerate(rewards)))\n",
    "          \n",
    "#     return np.random.choice(len(rewards),topn,p=prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generation  0  | Mean rewards:  4.711223790163793  | Mean of top 5:  9.083332753682326\n",
      "Top  20  scores [181  22  98 180 192  88 164  58  99 178  85 174 116 191 140  57 169  26\n",
      "  68 170]\n",
      "Rewards for top:  [12.57603362 11.47717307 11.26151573  5.05112292  5.05081843  5.05047046\n",
      "  5.05043336  5.0504318   5.05033303  5.0503172   5.05023939  5.0501885\n",
      "  5.05005282  5.05002641  5.04819906  5.04795637  5.04787358  5.04704898\n",
      "  5.04695164  5.04424956]\n",
      "t1= 2.4798130989074707\n",
      "Score for elite i  181  is  4.453003611962166\n",
      "Score for elite i  22  is  5.800576699367275\n",
      "Score for elite i  98  is  4.535098645468749\n",
      "Score for elite i  180  is  4.527806819443734\n",
      "Score for elite i  192  is  4.514853097830956\n",
      "Score for elite i  88  is  6.004891240334438\n",
      "Score for elite i  164  is  4.703100478876269\n",
      "Score for elite i  58  is  4.504437719558337\n",
      "Score for elite i  99  is  4.616206110473805\n",
      "Score for elite i  178  is  4.638001570666236\n",
      "Elite selected with index  88  and score 6.004891240334438\n",
      "t2= 12.974971055984497\n",
      "t3= 0.00571894645690918\n",
      "\n",
      "\n",
      "Generation  1  | Mean rewards:  5.064706572587136  | Mean of top 5:  12.961066311877312\n",
      "Top  20  scores [146 159  55  94  98  86 101  95 126 188 132   0  39 107 175  14  57  58\n",
      "  84  78]\n",
      "Rewards for top:  [14.93374906 12.57252935 12.48770899 12.40656076 12.4047834  11.54208707\n",
      " 11.50842276 11.41844386 11.41794573 11.39029707 11.2627797  11.1670422\n",
      " 10.71279401  5.0504536   5.05017929  5.05000816  5.04985424  5.04946126\n",
      "  5.04942412  5.04884273]\n",
      "t1= 2.4398179054260254\n",
      "Score for elite i  146  is  7.4105343922116065\n",
      "Score for elite i  159  is  4.494693530679651\n",
      "Score for elite i  55  is  4.5231507220789275\n",
      "Score for elite i  94  is  4.739857185494922\n",
      "Score for elite i  98  is  4.753583958571553\n",
      "Score for elite i  86  is  5.695443976363363\n",
      "Score for elite i  101  is  4.829150887294876\n",
      "Score for elite i  95  is  5.874389271304175\n",
      "Score for elite i  126  is  4.5056577120949655\n",
      "Score for elite i  188  is  4.802395815171193\n",
      "Score for elite i  199  is  4.63335687686717\n",
      "Elite selected with index  146  and score 7.4105343922116065\n",
      "t2= 12.894484996795654\n",
      "t3= 0.003061056137084961\n",
      "\n",
      "\n",
      "Generation  2  | Mean rewards:  4.860892147852857  | Mean of top 5:  12.861679308849933\n",
      "Top  20  scores [169  51  50 181 117 157  82  28   7  63  18   5  83  93   6 120 168 156\n",
      " 155 106]\n",
      "Rewards for top:  [14.26548573 13.34947271 12.57646676 12.5749271  11.54204424 11.54148683\n",
      "  5.05012855  5.05004755  5.04990866  5.04989864  5.04961045  5.04916209\n",
      "  5.04908651  5.04796918  5.04704692  5.04240528  4.85660578  4.81008383\n",
      "  4.81007053  4.80999473]\n",
      "t1= 2.683537721633911\n",
      "Score for elite i  169  is  4.547913638695974\n",
      "Score for elite i  51  is  4.530470992662179\n",
      "Score for elite i  50  is  4.76123779297978\n",
      "Score for elite i  181  is  4.5938001955520305\n",
      "Score for elite i  117  is  4.8813353051188475\n",
      "Score for elite i  157  is  6.085050054750383\n",
      "Score for elite i  82  is  4.731440116882405\n",
      "Score for elite i  28  is  4.695516570288497\n",
      "Score for elite i  7  is  4.351909488695254\n",
      "Score for elite i  63  is  4.4548162761463646\n",
      "Score for elite i  199  is  4.495101773427834\n",
      "Elite selected with index  157  and score 6.085050054750383\n",
      "t2= 13.510896921157837\n",
      "t3= 0.004212141036987305\n",
      "\n",
      "\n",
      "Generation  3  | Mean rewards:  4.674407619641907  | Mean of top 5:  7.634501967983079\n",
      "Top  20  scores [173  92 130  59 142  25  98 151  60 138 156 174 126  70 116 119 154  14\n",
      " 139  38]\n",
      "Rewards for top:  [11.54223605 11.47854206  5.05063621  5.05063536  5.05046016  5.0500375\n",
      "  5.05000641  5.04972922  5.04952174  5.04909508  5.04897791  5.04869917\n",
      "  5.04780216  4.85659814  4.83347798  4.81005819  4.81005392  4.78683241\n",
      "  4.78681261  4.78674879]\n",
      "t1= 3.133126974105835\n",
      "Score for elite i  173  is  4.7438632177255595\n",
      "Score for elite i  92  is  4.678501291045852\n",
      "Score for elite i  130  is  4.495280889258379\n",
      "Score for elite i  59  is  4.39746847617816\n",
      "Score for elite i  142  is  4.359263129089881\n",
      "Score for elite i  25  is  4.475795474396272\n",
      "Score for elite i  98  is  4.5481750800388046\n",
      "Score for elite i  151  is  4.507743810612779\n",
      "Score for elite i  60  is  4.714540057572286\n",
      "Score for elite i  138  is  6.218378059949801\n",
      "Score for elite i  199  is  4.553777525221757\n",
      "Elite selected with index  138  and score 6.218378059949801\n",
      "t2= 13.304134845733643\n",
      "t3= 0.0027420520782470703\n",
      "\n",
      "\n",
      "Generation  4  | Mean rewards:  4.863022728577962  | Mean of top 5:  12.69540832466294\n",
      "Top  20  scores [184 135  66 195 127  76 134 152  18  27 144  51   1 180 132  38  72  79\n",
      "  17  63]\n",
      "Rewards for top:  [13.86245079 12.67247659 12.57623582 12.57587937 11.78999906 11.54147553\n",
      "  5.050377    5.05028689  5.05018874  5.05004846  5.04974359  5.04962164\n",
      "  5.04944421  5.0493864   5.04930722  5.04901083  5.04884315  5.0483424\n",
      "  5.04791252  5.04744424]\n",
      "t1= 2.5460190773010254\n",
      "Score for elite i  184  is  4.526765067146413\n",
      "Score for elite i  135  is  4.695301836628188\n",
      "Score for elite i  66  is  4.630409757516626\n",
      "Score for elite i  195  is  4.444879887401273\n",
      "Score for elite i  127  is  4.771071614378248\n",
      "Score for elite i  76  is  4.734110815701227\n",
      "Score for elite i  134  is  4.668069739319545\n",
      "Score for elite i  152  is  4.508723775898785\n",
      "Score for elite i  18  is  4.537681788518736\n",
      "Score for elite i  27  is  6.006663209732467\n",
      "Score for elite i  199  is  4.57299022192718\n",
      "Elite selected with index  27  and score 6.006663209732467\n",
      "t2= 13.830978155136108\n",
      "t3= 0.002778768539428711\n",
      "\n",
      "\n",
      "Generation  5  | Mean rewards:  4.842446100698021  | Mean of top 5:  11.999283823367062\n",
      "Top  20  scores [  1  89  25 157  51  41 147 112 176  81  49 102  44  42 174  54  66  91\n",
      "  11 136]\n",
      "Rewards for top:  [12.57585701 12.57515357 12.26290803 11.540048   11.04245251 10.6996229\n",
      " 10.46485468  5.05067453  5.05049435  5.05045261  5.05014309  5.05012975\n",
      "  5.05010548  5.05005145  5.04981168  5.04875645  5.04871636  5.04853199\n",
      "  5.04704661  4.83334543]\n",
      "t1= 2.9652140140533447\n",
      "Score for elite i  1  is  4.540066740729946\n",
      "Score for elite i  89  is  6.122772966136984\n",
      "Score for elite i  25  is  4.448790354362101\n",
      "Score for elite i  157  is  4.703164933677205\n",
      "Score for elite i  51  is  4.48191959486294\n",
      "Score for elite i  41  is  6.169591244431636\n",
      "Score for elite i  147  is  4.72317930010758\n",
      "Score for elite i  112  is  6.042343490882975\n",
      "Score for elite i  176  is  4.6978930338624805\n",
      "Score for elite i  81  is  4.6349987348075405\n",
      "Score for elite i  199  is  4.692064771511315\n",
      "Elite selected with index  41  and score 6.169591244431636\n",
      "t2= 13.408565044403076\n",
      "t3= 0.0028421878814697266\n",
      "\n",
      "\n",
      "Generation  6  | Mean rewards:  4.87153690002822  | Mean of top 5:  12.231882833939768\n",
      "Top  20  scores [195 148  19 141  41 130 115 100 166  71 150 162 188 124  86 194 131  35\n",
      "  52  10]\n",
      "Rewards for top:  [13.86442751 12.66991504 11.54223742 11.54220259 11.54063161 11.26341607\n",
      " 10.45440546 10.10062115  5.05116228  5.05047063  5.05035499  5.05033728\n",
      "  5.04972945  5.04875929  5.04875549  5.04849766  5.04820562  5.04760851\n",
      "  4.81007774  4.81003351]\n",
      "t1= 2.544555902481079\n",
      "Score for elite i  195  is  4.545136565785438\n",
      "Score for elite i  148  is  4.581928352173337\n",
      "Score for elite i  19  is  4.583655307533798\n",
      "Score for elite i  141  is  4.818495002639487\n",
      "Score for elite i  41  is  4.7184714316356535\n",
      "Score for elite i  130  is  4.603035738746886\n",
      "Score for elite i  115  is  4.818422917813741\n",
      "Score for elite i  100  is  4.436352089281387\n",
      "Score for elite i  166  is  4.803810593609592\n",
      "Score for elite i  71  is  4.599681315774168\n",
      "Score for elite i  199  is  4.5856452711231475\n",
      "Elite selected with index  141  and score 4.818495002639487\n",
      "t2= 13.114838123321533\n",
      "t3= 0.0027840137481689453\n",
      "\n",
      "\n",
      "Generation  7  | Mean rewards:  4.876034676726708  | Mean of top 5:  12.155367886810392\n",
      "Top  20  scores [188 135  44 193 186 196 133 139  43 161 137  36 171  14 155  25  18 113\n",
      "  96  60]\n",
      "Rewards for top:  [12.57497061 12.57495543 12.57478047 11.54142064 11.51071229 11.47759943\n",
      " 11.21372116 10.46512772  5.05070209  5.05053737  5.05047104  5.05021534\n",
      "  5.04966778  5.04921876  5.0485141   5.04844642  5.0479684   5.04748364\n",
      "  5.04459116  4.83342683]\n",
      "t1= 2.4230151176452637\n",
      "Score for elite i  188  is  4.786959310152449\n",
      "Score for elite i  135  is  4.5516487910712655\n",
      "Score for elite i  44  is  4.589796457632913\n",
      "Score for elite i  193  is  4.679750986818359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for elite i  186  is  4.683002223217227\n",
      "Score for elite i  196  is  4.621852916801396\n",
      "Score for elite i  133  is  4.460287874640095\n",
      "Score for elite i  139  is  4.703290908462373\n",
      "Score for elite i  43  is  4.335109811674551\n",
      "Score for elite i  161  is  4.509400630832242\n",
      "Score for elite i  199  is  7.572599823100004\n",
      "Elite selected with index  199  and score 7.572599823100004\n",
      "t2= 13.855379104614258\n",
      "t3= 0.002531766891479492\n",
      "\n",
      "\n",
      "Generation  8  | Mean rewards:  4.775435815093121  | Mean of top 5:  11.768516352840951\n",
      "Top  20  scores [ 79 116  84 173  21  87  72  65 138 180  38  51 150 170  59 195  86 125\n",
      "  69  89]\n",
      "Rewards for top:  [12.5761937  12.57127317 11.26483458 11.2615855  11.16869482 10.72752573\n",
      "  5.05052007  5.05038324  5.05031631  5.04905774  5.04875448  5.04859567\n",
      "  5.04850857  5.04827462  5.04744007  5.04705295  5.04574193  4.81019178\n",
      "  4.81018236  4.80995293]\n",
      "t1= 2.4493072032928467\n",
      "Score for elite i  79  is  4.633203254937669\n",
      "Score for elite i  116  is  4.468885512316015\n",
      "Score for elite i  84  is  4.642556226048356\n",
      "Score for elite i  173  is  4.536083481975231\n",
      "Score for elite i  21  is  4.627979664327401\n",
      "Score for elite i  87  is  5.942669087333502\n",
      "Score for elite i  72  is  4.600660140667953\n",
      "Score for elite i  65  is  6.223703492254755\n",
      "Score for elite i  138  is  4.621493592893373\n",
      "Score for elite i  180  is  4.591688667560687\n",
      "Score for elite i  199  is  4.493192095305569\n",
      "Elite selected with index  65  and score 6.223703492254755\n",
      "t2= 13.095755815505981\n",
      "t3= 0.0031540393829345703\n",
      "\n",
      "\n",
      "Generation  9  | Mean rewards:  4.804910239016251  | Mean of top 5:  11.868498122234286\n",
      "Top  20  scores [ 80 116  41  24  35  78  51   1  69  87 188  56  10 101 149  47  25 168\n",
      "   7 112]\n",
      "Rewards for top:  [12.57540735 12.48811641 11.50933064 11.5082071  11.26142912  5.05070346\n",
      "  5.0504705   5.0503547   5.05033852  5.05033715  5.05029556  5.05018907\n",
      "  5.05000607  5.049984    5.04962306  5.04927805  5.0492007   5.04898125\n",
      "  5.04892229  5.04866167]\n",
      "t1= 2.6997811794281006\n",
      "Score for elite i  80  is  4.413328615233619\n",
      "Score for elite i  116  is  4.703227737540392\n",
      "Score for elite i  41  is  4.73193340269328\n",
      "Score for elite i  24  is  4.617366025131586\n",
      "Score for elite i  35  is  6.1514140306133624\n",
      "Score for elite i  78  is  4.491219662048794\n",
      "Score for elite i  51  is  6.323393564032258\n",
      "Score for elite i  1  is  4.178764652648683\n",
      "Score for elite i  69  is  4.688884963447715\n",
      "Score for elite i  87  is  4.830902291474182\n",
      "Score for elite i  199  is  4.809361088981642\n",
      "Elite selected with index  51  and score 6.323393564032258\n",
      "t2= 12.87518572807312\n",
      "t3= 0.002588987350463867\n"
     ]
    }
   ],
   "source": [
    "game_actions = 5 \n",
    "\n",
    "#disable gradients as we will not use them\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# initialize N number of agents\n",
    "num_agents = 200\n",
    "agents = return_random_agents(num_agents)\n",
    "\n",
    "# How many top agents to consider as parents\n",
    "top_limit = 20\n",
    "\n",
    "# run evolution until X generations\n",
    "generations = 10\n",
    "\n",
    "# thresold below which the agents will not give birth to children\n",
    "thr=0\n",
    "\n",
    "elite_index = None\n",
    "\n",
    "mean_reward=[]\n",
    "mean_top5_reward=[]\n",
    "top_reward=[]\n",
    "elite_reward=[]\n",
    "\n",
    "for generation in range(generations):\n",
    "#     print(generation)\n",
    "\n",
    "    # return rewards of agents\n",
    "    t1=time.time()\n",
    "    rewards = np.array(run_agents_n_times(agents, 1) )#return average of 3 runs\n",
    "#     print(rewards)\n",
    "#     print(\"\")\n",
    "\n",
    "    # sort by rewards\n",
    "#     print(np.argsort(rewards)[::-1][:top_limit])\n",
    "    sorted_parent_indexes = np.argsort(rewards)[::-1][:top_limit]\n",
    "    for p in range(top_limit):\n",
    "        if rewards[sorted_parent_indexes[p]]<thr:\n",
    "            sorted_parent_indexes=sorted_parent_indexes[:p]\n",
    "            break\n",
    "        \n",
    "#     sorted_parent_indexes = selection (generation,rewards,top_limit)\n",
    "#     print(sorted_parent_indexes)\n",
    "    #reverses and gives top values (argsort sorts by ascending by default) https://stackoverflow.com/questions/16486252/is-it-possible-to-use-argsort-in-descending-order\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "    top_rewards = np.zeros(top_limit)\n",
    "    p=0\n",
    "    for best_parent in sorted_parent_indexes:\n",
    "        top_rewards[p]=rewards[best_parent]\n",
    "        p=p+1\n",
    "    \n",
    "    print(\"Generation \", generation, \" | Mean rewards: \", np.mean(rewards), \" | Mean of top 5: \",np.mean(top_rewards[:5]))\n",
    "    #print(rewards)\n",
    "    print(\"Top \",top_limit,\" scores\", sorted_parent_indexes)\n",
    "    print(\"Rewards for top: \",top_rewards)\n",
    "    mean_reward.append(np.mean(rewards))\n",
    "    mean_top5_reward.append(np.mean(top_rewards[:5]))\n",
    "    top_reward.append(top_rewards[0])\n",
    "#     if top_rewards[0]>27:\n",
    "#         break\n",
    "    \n",
    "    # setup an empty list for containing children agents\n",
    "    t2=time.time()\n",
    "    print(\"t1=\",t2-t1)\n",
    "    n=np.int(np.round(len(sorted_parent_indexes)/top_limit*num_agents))\n",
    "    children_agents, elite_index, top_score = return_children(agents, sorted_parent_indexes, elite_index, n)\n",
    "    t3=time.time()\n",
    "    print(\"t2=\",t3-t2)\n",
    "    elite_reward.append(top_score)\n",
    "    # kill all agents, and replace them with their children\n",
    "    agents = children_agents\n",
    "    t4=time.time()\n",
    "    print(\"t3=\",t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2155, -0.1736,  0.0389,  0.2006,  0.1364,  0.1733,  0.1451, -0.2740,\n",
      "          0.0272,  0.2094,  0.1430,  0.0772,  0.2514],\n",
      "        [-0.0899,  0.1515,  0.0121,  0.0005, -0.1319,  0.1713,  0.0405,  0.0955,\n",
      "          0.2051,  0.2461, -0.1109,  0.0398, -0.0933],\n",
      "        [-0.0830, -0.0148,  0.1426, -0.0388, -0.2065,  0.2755,  0.2782,  0.2583,\n",
      "          0.2327,  0.1899, -0.2113,  0.0320,  0.0232],\n",
      "        [ 0.1912,  0.2823,  0.0088, -0.1708, -0.0067, -0.1617, -0.2742,  0.0788,\n",
      "          0.2003,  0.2388, -0.0368,  0.2032,  0.1599],\n",
      "        [-0.2472,  0.2593, -0.0391, -0.0882,  0.2518, -0.0654,  0.0042,  0.1246,\n",
      "          0.1130, -0.2551, -0.2467,  0.0364, -0.1356],\n",
      "        [-0.1232, -0.2210, -0.2856, -0.0115, -0.1659,  0.0148,  0.2312,  0.2545,\n",
      "          0.2535, -0.1834,  0.1492,  0.0255,  0.0622],\n",
      "        [ 0.0083, -0.1242,  0.0774, -0.2642,  0.1916,  0.2241,  0.1167,  0.0965,\n",
      "         -0.2440, -0.0981, -0.0991, -0.1195,  0.0498],\n",
      "        [-0.1662, -0.2201, -0.1211,  0.0565,  0.2106,  0.2136, -0.2716,  0.1510,\n",
      "          0.2159, -0.2030, -0.2900,  0.0967,  0.1938],\n",
      "        [ 0.1768, -0.1485, -0.1925,  0.0658, -0.1542, -0.0922,  0.0694, -0.1383,\n",
      "          0.2178,  0.2407,  0.0314,  0.1435, -0.2447],\n",
      "        [-0.2158, -0.2810,  0.0594, -0.1464,  0.1205,  0.2418,  0.1093, -0.0090,\n",
      "         -0.1597,  0.2128,  0.2657, -0.1190,  0.1592],\n",
      "        [ 0.1731, -0.1325,  0.1548,  0.0584,  0.0605, -0.0539,  0.0290,  0.2607,\n",
      "         -0.0848,  0.1223,  0.1747, -0.0366, -0.1629],\n",
      "        [-0.2485, -0.2323, -0.2074,  0.0879,  0.0548,  0.0873,  0.0198, -0.1782,\n",
      "         -0.0512, -0.1994, -0.1603,  0.1053, -0.0900],\n",
      "        [-0.2471,  0.1351,  0.0825, -0.0432, -0.1717, -0.0978, -0.0149,  0.2501,\n",
      "          0.1405,  0.1146, -0.0450,  0.1886, -0.1991],\n",
      "        [ 0.0102, -0.0889,  0.1484, -0.2046,  0.2201,  0.2977, -0.2250,  0.1099,\n",
      "         -0.0836, -0.1505, -0.0535,  0.1187,  0.1225],\n",
      "        [-0.2134,  0.0237,  0.0708, -0.1068, -0.2051,  0.1536,  0.1522,  0.1459,\n",
      "         -0.2220, -0.2251,  0.0533,  0.1535, -0.1173],\n",
      "        [ 0.2357,  0.2480, -0.1822,  0.0298, -0.2631, -0.0084, -0.0827, -0.1420,\n",
      "          0.1805,  0.1024, -0.0158, -0.2491,  0.0447],\n",
      "        [ 0.2170,  0.1840, -0.1398,  0.0473,  0.1754, -0.0721,  0.0933, -0.0518,\n",
      "          0.2049,  0.0673, -0.0917,  0.0136, -0.1135],\n",
      "        [ 0.0184,  0.2335,  0.0608,  0.1881, -0.0987, -0.1307, -0.0142,  0.2243,\n",
      "         -0.0272,  0.1889, -0.0724, -0.1514,  0.0114],\n",
      "        [-0.2924, -0.2723,  0.2118, -0.0341, -0.0498,  0.0546,  0.2303, -0.0604,\n",
      "          0.1928, -0.0795,  0.1040, -0.2748, -0.0710],\n",
      "        [ 0.0702,  0.1170, -0.0140, -0.1399,  0.0086, -0.0911,  0.1118,  0.2485,\n",
      "         -0.0453,  0.2405, -0.2112,  0.0938, -0.0350],\n",
      "        [ 0.1450,  0.1001, -0.2443,  0.0148, -0.1283, -0.1264, -0.2322,  0.2162,\n",
      "         -0.0830,  0.0536,  0.2282, -0.2618, -0.2331],\n",
      "        [-0.0395,  0.1228, -0.1935, -0.1747,  0.1478, -0.1076, -0.2324, -0.1558,\n",
      "          0.0329,  0.2569,  0.0443,  0.0332, -0.2569],\n",
      "        [-0.0639,  0.2001,  0.0934,  0.2525, -0.1377, -0.1496,  0.1102, -0.2423,\n",
      "         -0.0414, -0.0850,  0.0473,  0.0104,  0.1110],\n",
      "        [ 0.1788,  0.0051,  0.1820,  0.0308,  0.0714, -0.2370, -0.2362,  0.2356,\n",
      "          0.0054, -0.0210,  0.2319,  0.0157,  0.2142],\n",
      "        [-0.2086, -0.0153,  0.2263, -0.1111, -0.0492, -0.1436,  0.0262, -0.1821,\n",
      "          0.0470,  0.1569,  0.0324, -0.1375, -0.0389],\n",
      "        [ 0.0497,  0.2060, -0.1628,  0.1569, -0.1076,  0.0183, -0.0076,  0.2681,\n",
      "          0.0211, -0.2396,  0.0226, -0.1844,  0.1065],\n",
      "        [ 0.1698,  0.1289, -0.1856, -0.2364, -0.0386,  0.0631,  0.2276,  0.2341,\n",
      "          0.2346,  0.2497,  0.2372, -0.1388,  0.2699],\n",
      "        [-0.1086,  0.0116, -0.2469,  0.2257, -0.0894,  0.1375, -0.0265, -0.0929,\n",
      "         -0.1757,  0.0244,  0.2201,  0.0974,  0.1056],\n",
      "        [-0.0297,  0.1948, -0.2482,  0.2504,  0.2392,  0.0007,  0.0322, -0.1626,\n",
      "         -0.1262, -0.2158, -0.0463, -0.1336,  0.2484],\n",
      "        [-0.0465, -0.0974,  0.0848,  0.1729, -0.0609,  0.0541,  0.1201, -0.0762,\n",
      "          0.0086, -0.1896,  0.1165,  0.1412, -0.2094],\n",
      "        [ 0.1499, -0.0203, -0.0270, -0.0692,  0.0021, -0.1138, -0.1009,  0.0317,\n",
      "          0.2038,  0.1204, -0.2428, -0.1057,  0.1005],\n",
      "        [ 0.0026,  0.2680,  0.1255,  0.0637, -0.0547,  0.0611,  0.1955,  0.2471,\n",
      "          0.1682, -0.1590,  0.1862, -0.2831,  0.0118],\n",
      "        [-0.1534, -0.2602, -0.0010,  0.1438,  0.2428, -0.2673, -0.1531, -0.0652,\n",
      "          0.0795, -0.0441, -0.0237, -0.2321,  0.1508],\n",
      "        [ 0.0910, -0.1974,  0.0587,  0.1753,  0.0515, -0.1081,  0.1836,  0.1560,\n",
      "         -0.1456,  0.2546, -0.0936, -0.0897,  0.1910],\n",
      "        [ 0.1850, -0.1463, -0.0797,  0.1640, -0.2022,  0.2103,  0.1631, -0.1878,\n",
      "         -0.1808, -0.2606, -0.1068, -0.0203,  0.1734],\n",
      "        [-0.0101, -0.2291, -0.2156,  0.0737, -0.1481,  0.0719, -0.0731, -0.1582,\n",
      "          0.1832, -0.1522,  0.0256,  0.1008,  0.0973],\n",
      "        [ 0.2407, -0.1117, -0.1461,  0.0988, -0.1276,  0.1946, -0.0951, -0.2475,\n",
      "         -0.0472, -0.1073, -0.1787, -0.2281,  0.2346],\n",
      "        [-0.1622,  0.0366,  0.1574,  0.0415, -0.0261, -0.2561, -0.1389,  0.1613,\n",
      "         -0.0133,  0.1910, -0.0985,  0.1468,  0.0803],\n",
      "        [ 0.0123,  0.1799, -0.2020, -0.0758,  0.0541, -0.1844, -0.2470, -0.2054,\n",
      "          0.2379, -0.0024,  0.2708,  0.0118,  0.2021],\n",
      "        [ 0.1564, -0.1718, -0.2354, -0.1257, -0.1390,  0.1871, -0.1150, -0.1955,\n",
      "         -0.2326,  0.1390, -0.1534, -0.2081, -0.0529],\n",
      "        [ 0.1803, -0.0731, -0.1215,  0.1308, -0.1695,  0.1419, -0.0460,  0.0311,\n",
      "          0.0228,  0.1306, -0.0716,  0.2253, -0.2182],\n",
      "        [-0.2254, -0.0961,  0.0844,  0.1832, -0.1593,  0.0443, -0.1822,  0.0490,\n",
      "         -0.2659,  0.1044, -0.2041,  0.0480,  0.2697],\n",
      "        [-0.0005, -0.2564,  0.1188, -0.1427, -0.2287, -0.1148,  0.1086,  0.2032,\n",
      "         -0.0130,  0.1327,  0.1391, -0.1779, -0.0092],\n",
      "        [ 0.1397,  0.2644, -0.2317, -0.0392, -0.0142,  0.1656, -0.1131,  0.0109,\n",
      "         -0.2502,  0.0073, -0.0223, -0.0324,  0.1401],\n",
      "        [ 0.1360, -0.2218, -0.1583, -0.2220,  0.2592,  0.0854, -0.0995,  0.1773,\n",
      "          0.2443,  0.1280,  0.2467,  0.1568,  0.0576],\n",
      "        [ 0.2048,  0.0452, -0.1630,  0.1738, -0.1592,  0.1376,  0.0289, -0.2420,\n",
      "         -0.1065,  0.0323, -0.0832,  0.1396,  0.0423],\n",
      "        [-0.0662, -0.0857,  0.2429, -0.1951,  0.1082, -0.1105,  0.0111, -0.2017,\n",
      "         -0.1235,  0.1424,  0.2765, -0.1077,  0.2360],\n",
      "        [-0.0845,  0.2588,  0.1061, -0.0151, -0.2204, -0.0367,  0.1288,  0.1886,\n",
      "          0.2554, -0.1735, -0.1414, -0.1771, -0.0303],\n",
      "        [ 0.2435,  0.1580,  0.1150,  0.0870,  0.2035, -0.0132, -0.0961,  0.0553,\n",
      "          0.2064,  0.0776, -0.2102,  0.0650,  0.2909],\n",
      "        [-0.1465, -0.1350,  0.2291,  0.1935, -0.2031,  0.0347, -0.1609, -0.1563,\n",
      "          0.1510, -0.2580,  0.0354, -0.1694,  0.0263],\n",
      "        [ 0.1368, -0.2351,  0.2339, -0.2216, -0.0515, -0.2826,  0.0305, -0.2069,\n",
      "          0.1165, -0.0545,  0.1230,  0.1129, -0.1075],\n",
      "        [-0.0093, -0.2329,  0.0525, -0.2738,  0.0858, -0.0631, -0.2253, -0.2576,\n",
      "          0.0450, -0.1017, -0.0928, -0.0132,  0.0352],\n",
      "        [-0.2245, -0.0906, -0.1073, -0.1158,  0.1000,  0.1105, -0.1618, -0.2404,\n",
      "         -0.1455,  0.0771,  0.2587, -0.0358, -0.0240],\n",
      "        [ 0.2761, -0.1134,  0.0168, -0.1287,  0.0727,  0.1245, -0.0023,  0.0455,\n",
      "          0.2561, -0.2552, -0.0785, -0.0917, -0.1338],\n",
      "        [-0.0700,  0.0065,  0.1788, -0.1848,  0.1329,  0.0100, -0.0031, -0.2397,\n",
      "          0.0014, -0.0919,  0.2344,  0.1901,  0.1672],\n",
      "        [ 0.2610, -0.1084,  0.2661, -0.0735,  0.2312,  0.0391, -0.1813, -0.0510,\n",
      "         -0.2846, -0.1350, -0.0280, -0.0723, -0.1087],\n",
      "        [-0.0273,  0.0527, -0.0317, -0.2644, -0.1087, -0.0896,  0.0852, -0.2753,\n",
      "          0.1003, -0.0857, -0.0531, -0.1033, -0.1428],\n",
      "        [-0.0818,  0.1784,  0.1923, -0.2412, -0.0577, -0.1126, -0.0500, -0.0508,\n",
      "          0.0594,  0.1908,  0.0186,  0.0076,  0.2169],\n",
      "        [-0.1042,  0.0301, -0.0136,  0.0989,  0.0890,  0.1729,  0.2827, -0.2203,\n",
      "         -0.0817,  0.1772, -0.1127, -0.0413,  0.1788],\n",
      "        [ 0.1379,  0.1918,  0.1870, -0.1803,  0.0219,  0.2540,  0.1629, -0.2708,\n",
      "          0.0368, -0.1543, -0.2000,  0.1243, -0.0176],\n",
      "        [ 0.0749, -0.2170, -0.1985, -0.2793, -0.2065,  0.0227, -0.2135,  0.1052,\n",
      "         -0.1204,  0.0742,  0.0911,  0.2670, -0.2078],\n",
      "        [ 0.2415, -0.0687, -0.1882, -0.2331, -0.2066,  0.1003, -0.0646, -0.0657,\n",
      "         -0.2067,  0.0734,  0.1217, -0.1324, -0.2335],\n",
      "        [ 0.0509, -0.2290,  0.0387,  0.0738,  0.0360,  0.1670, -0.0915,  0.0539,\n",
      "          0.0226, -0.1976,  0.1439,  0.0532, -0.0037],\n",
      "        [-0.2259,  0.0627, -0.1772,  0.0502, -0.0829, -0.1255,  0.2768, -0.1140,\n",
      "         -0.1760,  0.0541,  0.1704,  0.0479, -0.0118]])\n",
      "tensor([-0.1665, -0.0055,  0.1133,  0.1175,  0.2284,  0.2436,  0.1607,  0.1403,\n",
      "         0.2857, -0.0763,  0.0185, -0.1161,  0.2539, -0.2135,  0.1909, -0.0257,\n",
      "        -0.0237,  0.1873,  0.1674, -0.0631,  0.1845,  0.0463, -0.2504, -0.1598,\n",
      "        -0.1843, -0.0211,  0.1646,  0.1300, -0.2141,  0.1007, -0.2183,  0.1739,\n",
      "         0.1068, -0.2804, -0.1209, -0.1566,  0.1824,  0.0163, -0.1463,  0.1819,\n",
      "        -0.2462, -0.2251,  0.2114,  0.1249, -0.0669, -0.2182,  0.0790, -0.0769,\n",
      "         0.2007, -0.2534,  0.2337,  0.0674,  0.0412,  0.2418, -0.1079,  0.0245,\n",
      "        -0.2535, -0.2657,  0.2261, -0.2119,  0.0171, -0.0743, -0.1453,  0.1352])\n",
      "tensor([[ 0.0384, -0.0131,  0.0069,  ..., -0.0465,  0.0667,  0.0558],\n",
      "        [-0.0869,  0.0102,  0.0774,  ..., -0.0281, -0.1380, -0.0842],\n",
      "        [ 0.0496, -0.1121, -0.0754,  ..., -0.0572, -0.0487,  0.0741],\n",
      "        ...,\n",
      "        [ 0.1441, -0.1365,  0.0808,  ..., -0.0905,  0.1078,  0.0614],\n",
      "        [-0.0937,  0.1272, -0.0859,  ..., -0.0149,  0.0751, -0.0869],\n",
      "        [-0.0132,  0.0506, -0.0681,  ..., -0.1052,  0.0680,  0.0863]])\n",
      "tensor([-0.1184,  0.0848, -0.0870, -0.0954,  0.0991,  0.0770,  0.0464, -0.0296,\n",
      "         0.0462, -0.0561, -0.1037,  0.0150, -0.0417,  0.0635, -0.0705, -0.0087,\n",
      "        -0.0703, -0.0593,  0.0755,  0.0682,  0.0896,  0.0787,  0.0233, -0.1051,\n",
      "        -0.1168, -0.1345,  0.0934, -0.0669, -0.0651, -0.0406, -0.1430,  0.1320,\n",
      "         0.0541, -0.1402,  0.0532, -0.0487, -0.0237, -0.0773,  0.0326,  0.0504,\n",
      "        -0.0863,  0.0587,  0.0759,  0.0015, -0.0012, -0.0022, -0.0023,  0.1087,\n",
      "         0.0840, -0.1073,  0.0626,  0.0949, -0.0401, -0.0027, -0.0101,  0.0548,\n",
      "         0.0897,  0.0233,  0.0895, -0.1234,  0.0742,  0.1377,  0.0061,  0.1053])\n",
      "tensor([[-0.0618,  0.1149, -0.0098, -0.1276,  0.0283, -0.0964,  0.0167, -0.0014,\n",
      "         -0.0176, -0.0645, -0.0084,  0.1124,  0.0530,  0.0073, -0.0483, -0.0148,\n",
      "         -0.0274, -0.0780, -0.0959,  0.0693,  0.0369, -0.0329,  0.1434,  0.0962,\n",
      "          0.1217, -0.0074,  0.1389, -0.0895, -0.0003, -0.0710,  0.0656, -0.1069,\n",
      "          0.0056,  0.0787,  0.0993,  0.0537, -0.1158, -0.1039, -0.0365,  0.0163,\n",
      "         -0.0023, -0.1109, -0.0411,  0.0128, -0.0355,  0.0850,  0.0642,  0.0397,\n",
      "         -0.1326,  0.0863,  0.1221,  0.0644, -0.0760,  0.1306, -0.0644, -0.0357,\n",
      "          0.0650,  0.0030,  0.0065, -0.0086,  0.0198,  0.0215,  0.0154,  0.0233],\n",
      "        [ 0.1328,  0.0275,  0.0021,  0.0498, -0.0804,  0.0901, -0.0650,  0.1180,\n",
      "          0.0120,  0.1434,  0.0049,  0.0136, -0.0852, -0.0468,  0.0375,  0.0498,\n",
      "          0.1028,  0.0604, -0.0506,  0.0623, -0.0049, -0.1186,  0.0739, -0.0800,\n",
      "          0.0898, -0.0369,  0.0806,  0.0347,  0.1117,  0.0276, -0.0614, -0.0966,\n",
      "          0.1392, -0.0438, -0.0239, -0.0125, -0.0614, -0.0599, -0.0803, -0.0425,\n",
      "          0.0035, -0.0686,  0.0027,  0.0294, -0.0147, -0.1289,  0.0787, -0.0767,\n",
      "          0.0343,  0.0027, -0.0268,  0.1317,  0.0659, -0.0221, -0.0746, -0.1145,\n",
      "          0.0001, -0.0457, -0.0242, -0.0924, -0.1135,  0.0788, -0.0945,  0.1170],\n",
      "        [ 0.0649, -0.0667,  0.0021, -0.0426, -0.1059,  0.0030,  0.0155,  0.1180,\n",
      "         -0.0250, -0.1048, -0.0789, -0.1130, -0.0411, -0.0802, -0.1600,  0.0613,\n",
      "          0.0793,  0.0939, -0.0206,  0.0759,  0.0700,  0.0555,  0.0900, -0.0471,\n",
      "          0.0648, -0.0203,  0.0202, -0.0351, -0.0558,  0.1143, -0.1005,  0.0595,\n",
      "         -0.1249,  0.0355,  0.0822,  0.0869, -0.0042, -0.0065, -0.0803, -0.1269,\n",
      "         -0.0929, -0.1133, -0.1099,  0.0737, -0.0163,  0.0253,  0.0705, -0.0751,\n",
      "          0.0272, -0.0557,  0.0869, -0.0730, -0.0974, -0.0467,  0.1207, -0.1146,\n",
      "          0.1109, -0.1086,  0.0928, -0.1045,  0.0940,  0.0498, -0.1152, -0.1105],\n",
      "        [-0.1179, -0.0841, -0.0879,  0.1074, -0.0909,  0.0912, -0.0618, -0.0365,\n",
      "         -0.0164,  0.0851, -0.0756, -0.0367,  0.0373,  0.0366, -0.0573,  0.0208,\n",
      "          0.1230,  0.0170, -0.0055, -0.0318, -0.0176, -0.1208,  0.0133, -0.0090,\n",
      "         -0.0304, -0.0690,  0.0804, -0.0787, -0.1028, -0.0954, -0.0427,  0.1441,\n",
      "         -0.0074, -0.0822,  0.0208,  0.0280,  0.1191, -0.0221, -0.0884, -0.0122,\n",
      "          0.0541, -0.0469, -0.1240, -0.0505, -0.0956,  0.0852,  0.0524,  0.0677,\n",
      "         -0.0931,  0.0815, -0.0300,  0.0866, -0.1057,  0.0820,  0.0781,  0.0283,\n",
      "          0.0840, -0.0696,  0.0240, -0.0792, -0.1397, -0.0157,  0.0464,  0.0992],\n",
      "        [ 0.0744, -0.0091,  0.1229,  0.0899,  0.0193, -0.0183,  0.0764, -0.0996,\n",
      "          0.0115,  0.0480,  0.1038,  0.1048,  0.1048, -0.0783,  0.1058, -0.0343,\n",
      "          0.0724, -0.0226,  0.1133, -0.0206,  0.1020,  0.0877,  0.0090, -0.0209,\n",
      "          0.0935,  0.0316, -0.0468, -0.1459, -0.0014,  0.0018,  0.0043, -0.1229,\n",
      "         -0.0015,  0.1155, -0.0376, -0.0314,  0.0314,  0.0413,  0.0942, -0.0879,\n",
      "          0.1135,  0.0175,  0.1014,  0.0345, -0.0977, -0.0514, -0.1060, -0.1225,\n",
      "         -0.0129, -0.0452,  0.0692, -0.0101,  0.0000,  0.0230, -0.0551, -0.0880,\n",
      "          0.0228, -0.0845, -0.0595,  0.0813, -0.0204,  0.0037, -0.0838,  0.1346]])\n",
      "tensor([ 0.0324,  0.0777,  0.0514,  0.0039, -0.0698])\n"
     ]
    }
   ],
   "source": [
    "for param in agents[51].parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('GA-2layer-64.csv',np.array([mean_reward,mean_top5_reward,top_reward,elite_reward]).T,fmt=['%.7f','%.7f','%.7f','%.7f'],delimiter=',',header=\"mean_reward,mean_top5_reward,top_reward,elite_reward\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(5,4),tight_layout=True)\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "\n",
    "ax.plot(mean_reward)\n",
    "ax.plot(mean_top5_reward)\n",
    "ax.plot(top_reward)\n",
    "ax.plot(elite_reward)\n",
    "\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "\n",
    "ax.set(xlabel='Generation', ylabel='Reward',\n",
    "       title='Jt=8.18e-3')        ### The 12 pulse sequence is compared with the 6 pulse sequence\n",
    "                                   ### We regard the 6 pulse sequence is T long, the 12 pulse sequence is 2T long \n",
    "\n",
    "plt.legend(['mean_reward', 'mean_top5_reward','top_reward', 'elite_reward'], loc='best')\n",
    "\n",
    "plt.savefig('GA-2layer-64.eps', dpi=fig.dpi, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_agent(agent):\n",
    "#     try: #try and exception block because, render hangs if an erorr occurs, we must do env.close to continue working    \n",
    "        env = gym.make('xy-v0')\n",
    "\n",
    "\n",
    "        maxTime=12\n",
    "        nSpin=3\n",
    "        min_delay=0\n",
    "        max_delay=1\n",
    "        pw=0.0\n",
    "        env.setParam(maxTime,nSpin,min_delay,max_delay,pw)\n",
    "\n",
    "\n",
    "\n",
    "        Aim=np.zeros([2**nSpin,2**nSpin])\n",
    "        env.setTargetH(Aim)\n",
    "        env.setTarget(expm(-1j*Aim))\n",
    "\n",
    "        H=Hamiltonian(nSpin,'p',[1],[-0.5,-0.5,1,0])\n",
    "        J=8.18e-3\n",
    "        env.setH0(J*H) \n",
    "        env.set_pulse()\n",
    "        \n",
    "        observation,info = env.reset()\n",
    "        last_observation = observation\n",
    "        r=0\n",
    "        for i in range(12):\n",
    "#             env_record.render()\n",
    "            inp = torch.tensor(observation).type('torch.FloatTensor').view(1,-1)\n",
    "            output_probabilities = agent(inp).detach().numpy()[0]\n",
    "            action = np.random.choice(range(game_actions), 1, p=output_probabilities).item()\n",
    "            print(action)\n",
    "            new_observation, reward, done, info = env.step(action,i)\n",
    "            r=r+reward\n",
    "            observation = new_observation\n",
    "\n",
    "            if(done):\n",
    "                break\n",
    "\n",
    "#         env_record.close()\n",
    "        print(\"Rewards: \",r)\n",
    "        print(observation)\n",
    "\n",
    "#     except Exception as e:\n",
    "# #         env_record.close()\n",
    "#         print(e.__doc__)\n",
    "#         print(e.message)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_agent(agents[406])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent():\n",
    "#     try: #try and exception block because, render hangs if an erorr occurs, we must do env.close to continue working    \n",
    "    env = gym.make('xy-v0')\n",
    "\n",
    "\n",
    "    maxTime=12\n",
    "    nSpin=3\n",
    "    min_delay=0\n",
    "    max_delay=1\n",
    "    pw=0.5\n",
    "    env.setParam(maxTime,nSpin,min_delay,max_delay,pw)\n",
    "\n",
    "\n",
    "    Aim=np.zeros([2**nSpin,2**nSpin])\n",
    "    env.setTargetH(Aim)\n",
    "    env.setTarget(expm(-1j*Aim))\n",
    "\n",
    "    H=Hamiltonian(nSpin,'p',[1],[-0.5,-0.5,1,0])\n",
    "    J=8.18e-3\n",
    "    env.setH0(J*H)  \n",
    "    env.set_pulse()\n",
    "\n",
    "    observation,info = env.reset()\n",
    "    last_observation = observation\n",
    "    r=0\n",
    "\n",
    "\n",
    "    new_observation, reward, done, info = env.step(0,0)\n",
    "    new_observation, reward, done, info = env.step(0,1)\n",
    "    new_observation, reward, done, info = env.step(0,2)\n",
    "    new_observation, reward, done, info = env.step(0,3)\n",
    "    new_observation, reward, done, info = env.step(0,4)\n",
    "    new_observation, reward, done, info = env.step(0,5)\n",
    "    new_observation, reward, done, info = env.step(0,6)\n",
    "    new_observation, reward, done, info = env.step(0,7)\n",
    "    new_observation, reward, done, info = env.step(0,8)\n",
    "    new_observation, reward, done, info = env.step(0,9)\n",
    "    new_observation, reward, done, info = env.step(0,10)\n",
    "    new_observation, reward, done, info = env.step(0,11)\n",
    "    r=r+reward\n",
    "#         H1=env.getAHT1()\n",
    "#         H2=env.getAHT2()\n",
    "#         H3=env.getAHT3()\n",
    "# #         H4=env.getAHT4()\n",
    "# #         print(np.trace(np.transpose(np.conjugate(H1))*H1))\n",
    "# #         print(np.trace(np.transpose(np.conjugate(H2))*H2))\n",
    "# #         print(np.trace(np.transpose(np.conjugate(H3))*H3))\n",
    "# #         print(np.trace(np.transpose(np.conjugate(H4))*H4))\n",
    "#         print(-np.log(1-np.trace(expm(-1j*H1))/8))\n",
    "#         print(-np.log(1-np.trace(expm(-1j*(H1+H2)))/8))\n",
    "#         print(-np.log(1-np.trace(expm(-1j*(H1+H2+H3)))/8))\n",
    "#         print('fidelity')\n",
    "#         print(np.abs(np.sum(H1*np.transpose(np.conjugate(self.target)))/2**self.nSpin))\n",
    "\n",
    "#         if(done):\n",
    "#             break\n",
    "\n",
    "    print(\"Rewards: \",r)\n",
    "    print(new_observation)\n",
    "\n",
    "#     except Exception as e:\n",
    "# #         env_record.close()\n",
    "#         print(e.__doc__)\n",
    "#         print(e.message)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards:  3.7968786620056614\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 13.]\n"
     ]
    }
   ],
   "source": [
    "test_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.20026468,  4.75683489,  4.47893433,  4.20026468,  4.75683489,\n",
       "        4.25929634,  4.20025411,  4.75683498,  4.85655181,  4.47463106,\n",
       "        4.47363875,  4.85645689,  4.76332941,  4.20614659,  4.20028438,\n",
       "        4.76086057,  4.75683489, 10.09999789,  4.20032263,  4.25086378,\n",
       "        4.85659807,  4.47363867,  4.47363875,  4.47363875,  4.85561182,\n",
       "        4.29518203,  4.20032263,  4.75875322,  4.25792733, 10.15558136,\n",
       "        4.20032263,  4.47363875,  4.20027675,  4.75683489,  5.0445914 ,\n",
       "        4.7586833 ,  4.85597721, 10.18778316,  4.75683489,  4.29518203,\n",
       "        4.85561182,  4.75683525,  9.05901162,  4.85561182,  4.7600458 ,\n",
       "        4.75683489,  4.47496121,  4.85561182, 11.2871902 ,  4.75683489,\n",
       "        4.11179721,  4.75683489,  4.75683489,  4.76118621,  4.85561182,\n",
       "        4.75683489,  4.47893433,  4.7609758 ,  4.47328921,  4.85597721,\n",
       "        4.20029046,  4.68518759,  4.20032263,  4.25718992,  4.7586833 ,\n",
       "        4.20032263,  4.47496121,  4.47882569,  4.25929634,  4.85645689,\n",
       "        4.47363875,  4.85561182,  4.85561182,  4.76013544,  4.75683489,\n",
       "        4.47297285,  4.20032263,  4.75868381,  9.05901162,  5.04672969,\n",
       "        4.75973553,  4.8098175 ,  4.85561182,  4.47034151,  4.47363875,\n",
       "       10.18766087,  4.85561182,  4.20029046,  4.75868339,  4.47562312,\n",
       "        4.20032263,  4.47362415,  4.20032263,  4.25719374,  4.47396949,\n",
       "        4.85561182,  4.76012733,  4.85645689,  4.47692775,  4.76013318,\n",
       "        4.47496221,  4.85561182,  4.20060036,  4.7866938 ,  4.85597721,\n",
       "        4.47363875,  4.47363922,  4.47363875,  5.04410173,  4.20026468,\n",
       "        4.47363875,  4.47363828,  4.75683495,  4.76009945,  4.47322259,\n",
       "        4.69200927,  4.85561182,  4.75687622,  4.75683495,  9.89419524,\n",
       "        4.85561182,  4.7611671 ,  4.85561182,  5.04375796,  4.20032263,\n",
       "        4.47926134,  4.76089578,  4.75683489,  4.29518203,  4.20255259,\n",
       "        4.47893433,  4.76086018,  4.85561182, 11.26179699,  4.76118635,\n",
       "        4.47683626,  4.75683495,  4.4786718 ,  4.6796541 ,  4.20032263,\n",
       "        4.47718697,  4.7601753 ,  4.4769332 ,  4.76126155,  4.6771548 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rewards)[np.array(rewards)>4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(rewards)[::-1][:top_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents1=return_random_agents(2)\n",
    "agents2=return_random_agents(2)\n",
    "agents1.append(agents2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CartPoleAI(\n",
       "   (fc): Sequential(\n",
       "     (0): Linear(in_features=13, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=64, out_features=5, bias=True)\n",
       "     (5): Softmax()\n",
       "   )\n",
       " ), CartPoleAI(\n",
       "   (fc): Sequential(\n",
       "     (0): Linear(in_features=13, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=64, out_features=5, bias=True)\n",
       "     (5): Softmax()\n",
       "   )\n",
       " ), CartPoleAI(\n",
       "   (fc): Sequential(\n",
       "     (0): Linear(in_features=13, out_features=64, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (3): ReLU()\n",
       "     (4): Linear(in_features=64, out_features=5, bias=True)\n",
       "     (5): Softmax()\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
